from __future__ import annotations
import re

import pytesseract
from PIL import Image
from io import BytesIO
import json

import logging
import sys
import os
from datetime import datetime, timedelta
from typing import Any
from urllib.parse import urljoin
import requests
from bs4 import BeautifulSoup
from zoneinfo import ZoneInfo
import numpy as np
import cv2
from google import genai  # ì‹ í˜• ë¼ì´ë¸ŒëŸ¬ë¦¬
from dotenv import load_dotenv
RECIPIENTS_DEFAULT = [
    {"name": "ê´€ë¦¬ì", "contact": "01026570090"} 
]
BOARDS_DEFAULT = [
    {"name": "í•™ë¶€ê³µì§€", "category": "notice_under"},
    {"name": "í•™ë¶€ì¥í•™", "category": "scholarship_under"},
    {"name": "ì •ë³´ëŒ€ì†Œì‹", "category": "news"},
    {"name": "ì·¨ì—…ì •ë³´", "category": "course_job"},
    {"name": "í”„ë¡œê·¸ë¨", "category": "course_program"},
    {"name": "ì¸í„´ì‹­", "category": "course_intern"},
    {"name": "ê³µëª¨ì „", "category": "course_competition"},
]

session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
})

print("########################################")
print("#  THIS IS  - FINAL CHECK    #")
print("########################################")
load_dotenv() # .env íŒŒì¼ì„ ì½ì–´ì„œ os.getenvê°€ ê°’ì„ ì°¾ì„ ìˆ˜ ìˆê²Œ í•´ì¤Œ

def preprocess_for_ocr(pil_img: Image.Image) -> Image.Image:
    img = np.array(pil_img)
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    _, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)
    return Image.fromarray(thresh)
logger = logging.getLogger()
logger.setLevel(logging.INFO)
pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'
def extract_text_from_image(img_url: str, parent_link: str) -> str:
    try:
        resp = session.get(img_url, timeout=HTTP_TIMEOUT)
        # ë¡œê·¸ì— ì›ë³¸ ê²Œì‹œê¸€ ë§í¬(parent_link)ë¥¼ í¬í•¨í•˜ì—¬ ì¶œë ¥
        LOG.info(f"ğŸ“¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„: {img_url} (ì¶œì²˜: {parent_link})")
        LOG.info(f"   â”” ì‘ë‹µ: {resp.status_code}, íƒ€ì…: {resp.headers.get('Content-Type')}")

        if "image" not in resp.headers.get("Content-Type", "").lower():
            LOG.error(f"   â”” ì‹¤íŒ¨: ì´ë¯¸ì§€ê°€ ì•„ë‹˜ ({img_url})")
            return ""

        img = Image.open(BytesIO(resp.content))
        processed = preprocess_for_ocr(img)

        text = pytesseract.image_to_string(
            processed,
            lang="kor+eng",
            config="--oem 3 --psm 6"
        )
        LOG.info(f"   â”” OCR ì²˜ë¦¬ ì™„ë£Œ (ê¸€ì ìˆ˜: {len(text.strip())})")
        return text.strip()
    except Exception as e:
        LOG.error(f"   â”” OCR ì‹¤íŒ¨ ({img_url}): {e}")
        return ""

# --- ì¶”ê°€ëœ 2ì°¨ í¬ë¡¤ë§ í•¨ìˆ˜ ---
def fetch_post_content(link: str) -> tuple[str, list[str]]:
    try:
        resp = requests.session.get(link, timeout=HTTP_TIMEOUT)
        resp.encoding = 'utf-8'
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        
        # 1. ë³¸ë¬¸ ì˜ì—­ íƒìƒ‰ (ê°€ì¥ ì •í™•í•œ ì„ íƒì ìˆœì„œ)
        # ì •ë³´ëŒ€ ê²Œì‹œë¬¼ì€ ë³´í†µ .view-con ì•ˆì— .fr-viewê°€ ë“¤ì–´ìˆëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.
        content_area = (
                soup.select_one(".view-con") or 
                soup.select_one(".fr-view") or 
                soup.select_one("#article_text") or # ì¶”ê°€
                soup.select_one(".board-view-content") # ì¶”ê°€
            )
        
        if content_area:
            text = content_area.get_text(" ", strip=True)
            
            # 2. ì´ë¯¸ì§€ ì¶”ì¶œ (ë³´ì—¬ì£¼ì‹  íƒœê·¸ êµ¬ì¡° ë°˜ì˜)
            img_tags = content_area.find_all("img")
            img_urls = []
            
            for img in img_tags:
                # srcì™€ data-pathë¥¼ ëª¨ë‘ í™•ì¸
                src = img.get("src") or img.get("data-path")
                
                if src:
                    # í•„í„°ë§: ì—ë””í„° ì•„ì´ì½˜ì´ë‚˜ ì•„ì£¼ ì‘ì€ ì´ë¯¸ì§€ëŠ” ì œì™¸ (OCR íš¨ìœ¨ì„±)
                    if any(x in src for x in ["/icon/", "base64", "emoji"]):
                        continue
                    
                    # ìƒëŒ€ ê²½ë¡œ(/_res/...)ë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ê²°í•©
                    # urljoinì€ linkê°€ https://info.korea.ac.kr/... ì´ë¯€ë¡œ ì•Œì•„ì„œ í•©ì³ì¤ë‹ˆë‹¤.
                    full_url = urljoin(link, src)
                    img_urls.append(full_url)
            
            LOG.info(f"âœ… ì´ë¯¸ì§€ ê°ì§€ ì„±ê³µ: {len(img_urls)}ê°œ ë°œê²¬ (URL: {link})")
            return text, img_urls
            
        LOG.warning(f"âš ï¸ ë³¸ë¬¸ ì˜ì—­ íƒìƒ‰ ì‹¤íŒ¨: {link}")
        return "ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
        
    except Exception as e:
        LOG.error(f"âŒ 2ì°¨ í¬ë¡¤ë§ ì—ëŸ¬: {e}")
        return f"ì—ëŸ¬ ë°œìƒ: {e}", []
    
BASE_URL_DEFAULT = "https://info.korea.ac.kr/info/board/"
HTTP_TIMEOUT = float(os.getenv("HTTP_TIMEOUT", "15"))
SENDER_KEY = os.getenv("KAKAO_SENDER_KEY")
SECRET_KEY = os.getenv("KAKAO_SECRET_KEY")
APP_KEY = os.getenv("KAKAO_APP_KEY")
TEMPLATE_CODE = "send-article"
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)] 
)
LOG = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
LOOKBACK_DAYS = int(os.getenv("LOOKBACK_DAYS", "7"))
TIMEZONE = ZoneInfo("Asia/Seoul")

# [í•µì‹¬ ìˆ˜ì •] ì‹ í˜• ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì • ë°©ì‹
if GEMINI_API_KEY:
    client = genai.Client(api_key=GEMINI_API_KEY)
else:
    LOG.warning("GEMINI_API_KEY is missing!")
    client = None
def ask_ai(prompt: str) -> tuple[float, str]:
    try:
        LOG.info("=== [AI CALL START] ===")
        
        # 1. í”„ë¡¬í”„íŠ¸ ìœ ë‹ˆì½”ë“œ ì•ˆì „í™” (UTF-8 ê°•ì œ)
        # ë§Œì•½ promptê°€ ìœ ë‹ˆì½”ë“œê°€ ì•„ë‹ˆë¼ë©´ ê°•ì œë¡œ utf-8ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        if isinstance(prompt, bytes):
            safe_prompt = prompt.decode('utf-8')
        else:
            safe_prompt = str(prompt)

        if not client:
            LOG.error("âŒ ì—ëŸ¬: Gemini Clientê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return 0.0, "no-client"

        # 2. Gemini ëª¨ë¸ í˜¸ì¶œ (168ë¼ì¸ ë¶€ê·¼)
        LOG.info(f"ğŸ¤– Calling model: gemini-2.0-flash... (Prompt size: {len(safe_prompt)})")
        # [í•µì‹¬] ëŸ°íƒ€ì„ì—ì„œ ì¸ì½”ë”© ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ 
        # ì‹œìŠ¤í…œ í™˜ê²½ì´d ê¹¨ì ¸ìˆì–´ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ UTF-8ì„ ì‚¬ìš©í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=safe_prompt, 
            config={
                'tools': [],
                'automatic_function_calling': {'disable': True}
            }
        )
        print(4)
        # 3. ì‘ë‹µ ì²˜ë¦¬ ë° ë¡œê·¸ ì¶œë ¥ ì‹œ ì¸ì½”ë”© ë°©ì–´
        # response.textê°€ í•œê¸€ì¼ ë•Œ LOG.infoì—ì„œ í„°ì§€ëŠ” ê²ƒì„ repr()ë¡œ ë°©ì–´í•©ë‹ˆë‹¤.
        raw_text = response.text if response.text else ""
        LOG.info(f"ğŸ“¥ Raw Response Received: {repr(raw_text)}")

        if not raw_text.strip():
            LOG.warning("âš ï¸ AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return 0.0, "empty-response"

        # 4. JSON íŒŒì‹±
        LOG.info("ğŸ§© Parsing JSON from response...")
        json_match = re.search(r"\{.*\}", raw_text, re.DOTALL)
        
        if json_match:
            clean_json = json_match.group(0)
            data = json.loads(clean_json)
            score = float(data.get("score", 0.0))
            reason = data.get("reason", "ë¶„ì„ ì™„ë£Œ")
            
            # ì‚¬ìœ (reason) ì¶œë ¥ ì‹œì—ë„ repr() ì‚¬ìš©
            LOG.info(f"ğŸ¯ Analysis Result - Score: {score}, Reason: {repr(reason)}")
            LOG.info("=== [AI CALL SUCCESS] ===")
            return score, reason
        else:
            LOG.error(f"âŒ JSON íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ë¬¸: {repr(raw_text)}")
            raise ValueError("JSON format not found in response")

    except Exception as e:
        # ì—ëŸ¬ ë©”ì‹œì§€ ìì²´(ì˜ˆ: 'ë³¸ì¸ì˜_í‚¤')ë¥¼ ì¶œë ¥í•˜ë‹¤ í„°ì§€ì§€ ì•Šê²Œ repr(e) ì²˜ë¦¬
        LOG.error(f"ğŸ’¥ Critical Error in ask_ai: {repr(e)}")
        import traceback
        LOG.error(traceback.format_exc())
        return 0.0, f"failure: {repr(str(e))}"
def score_notice(profile_text: str, title: str, link: str) -> tuple[float, str]:
    if not profile_text: return 0.0, "no-profile"
    
    # [ìˆ˜ì •] AIì—ê²Œ ì ìˆ˜(0~1)ë¥¼ ì§ì ‘ ìš”êµ¬í•˜ì—¬ relevanceScore ìƒì„±
    user_prompt = f"""
    Profile: {profile_text}
    Notice Title: {title}
    Analyze how relevant this notice is to the profile. 
    Respond with a JSON object: {{"score": float, "reason": "short explanation in Korean"}}
    The score must be between 0.0 and 1.0.
    Respond ONLY with a valid JSON object. Do not include markdown code blocks
    """
    
    try:
        response_text = ask_ai(user_prompt)
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ê°€ì¥ ê°„ë‹¨í•œ ë°©ì‹)
        start = response_text.find('{')
        end = response_text.rfind('}') + 1
        res_json = json.loads(response_text[start:end])
        return float(res_json.get("score", 0.0)), res_json.get("reason", "ë¶„ì„ ì™„ë£Œ")
    except:
        return 0.0, "AI ë¶„ì„ ì‹¤íŒ¨"


def normalize_base(url: str | None) -> str:
    if not url:
        return BASE_URL_DEFAULT
    trimmed = url.strip()
    if trimmed.endswith(".do"):
        trimmed = trimmed[: trimmed.rfind("/") + 1]
    return f"{trimmed.rstrip('/')}/"

# [ì¶”ê°€] AI ì œê³µìë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„ íƒ (ê¸°ë³¸ê°’: gemini)
AI_PROVIDER = os.getenv("AI_PROVIDER", "gemini").lower() 
# OpenAI í‚¤ë„ í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ ë¶ˆëŸ¬ì˜¤ê¸° (ë‚˜ì¤‘ì„ ìœ„í•´)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = genai.Client(api_key=GEMINI_API_KEY) if GEMINI_API_KEY else None
# app/jobs/korea_university.py ë‚´ send_kakao ìˆ˜ì •

# app/jobs/korea_university.py ì˜ send_kakao í•¨ìˆ˜ ìˆ˜ì •
def send_kakao(contact: str, template_code: str, template_param: dict[str, str]) -> dict[str, Any]:
    payload = {
        "senderKey": SENDER_KEY,
        "templateCode": template_code,
        "recipientList": [{"recipientNo": contact, "templateParameter": template_param}],
    }
    headers = {"X-Secret-Key": SECRET_KEY, "Content-Type": "application/json;charset=UTF-8"}
    url = f"https://api-alimtalk.cloud.toast.com/alimtalk/v2.2/appkeys/{APP_KEY}/messages"
    
    try:
        # [ìˆ˜ì •] POST ìš”ì²­ì´ ë¨¼ì € ì™€ì•¼ í•©ë‹ˆë‹¤.
        resp = session.post(url, json=payload, headers=headers, timeout=HTTP_TIMEOUT)
        # [ìˆ˜ì •] ê·¸ í›„ì— ë¡œê·¸ë¥¼ ì°ì–´ì•¼ NameErrorê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        LOG.info(f"Kakao API ì‘ë‹µ ìƒíƒœ: {resp.status_code}")
        LOG.info(f"Kakao API ì‘ë‹µ ë³¸ë¬¸: {resp.text}")
        if resp.status_code != 200:
            LOG.error("Kakao send failed (%s) %s", resp.status_code, resp.text)
            return {"error": "API_STATUS_ERROR", "status": resp.status_code}
            
        return resp.json() if "application/json" in resp.headers.get("Content-Type", "") else {"status": resp.status_code}
    except Exception as e:
        LOG.error("Kakao connection error: %s", e)
        return {"error": str(e)}
def fetch_board(base_url: str, board: dict[str, str]) -> tuple[str, str]:
    page_url = f"{base_url}{board['category']}.do"
    resp = session.get(page_url, timeout=HTTP_TIMEOUT)
    resp.raise_for_status()
    return page_url, resp.text


def parse_posts(html: str, page_url: str) -> list[dict[str, str]]:
    soup = BeautifulSoup(html, "html.parser")
    today = datetime.now(TIMEZONE).date()
    cutoff = today - timedelta(days=LOOKBACK_DAYS - 1)
    posts: list[dict[str, str]] = []
    
    for row in soup.select("tr"):
        cells = row.find_all("td")
        if not cells:
            continue
        
        # ë‚ ì§œ íŒŒì‹± (ê³ ë ¤ëŒ€ í˜•ì‹: YYYY.MM.DD)
        date_text = cells[-1].get_text(strip=True)
        try:
            row_date = datetime.strptime(date_text, "%Y.%m.%d").date()
        except ValueError:
            continue
            
        if row_date < cutoff:
            continue
            
        link_tag = row.select_one("a.article-title")
        if not link_tag:
            continue
            
        href = (link_tag.get("href") or "").replace("amp;", "")
        title = link_tag.get_text(strip=True)
        posts.append({"title": title, "link": urljoin(page_url, href)})
        
    return posts


def evaluate_posts(profile_text: str, board_name: str, posts: list[dict[str, str]]) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:
    aligned: list[dict[str, Any]] = []
    evaluated: list[dict[str, Any]] = []
    
    for post in posts:
        post_copy = dict(post)
        decision, rationale = score_notice(profile_text, post_copy["title"], post_copy["link"])
        post_copy["reason"] = rationale
        post_copy["aligned"] = decision
        
        # í•„ë“œ ì´ˆê¸°í™”
        post_copy["full_content"] = ""
        post_copy["images"] = []

        if decision: 
            LOG.info(f"ğŸ” [ë¶„ì„ ì‹œì‘] ì œëª©: {post_copy['title']}")
            full_text, img_urls = fetch_post_content(post_copy["link"])
            
            ocr_combined_text = ""
            for idx, url in enumerate(img_urls):
                # ì´ë¯¸ì§€ë³„ë¡œ ìˆœë²ˆê³¼ ë§í¬ë¥¼ ë¡œê·¸ì— ë‚¨ê¹€
                ocr_result = extract_text_from_image(url, post_copy["link"])
                if ocr_result:
                    ocr_combined_text += f"\n\n--- [ì´ë¯¸ì§€ #{idx+1} í…ìŠ¤íŠ¸ ì‹œì‘] ---\n{ocr_result}\n--- [ì´ë¯¸ì§€ #{idx+1} í…ìŠ¤íŠ¸ ë] ---\n"
            
            # ìµœì¢… ê²°í•© ë° í• ë‹¹
            post_copy["full_content"] = (full_text + ocr_combined_text).strip()
            post_copy["images"] = img_urls

            # ë¡œê·¸ë¡œ ê²°í•© ê²°ê³¼ í™•ì¸
            LOG.info(f"ğŸ“Š [ê²°í•© ì™„ë£Œ] {post_copy['title']}")
            LOG.info(f"   â”” ë³¸ë¬¸ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_text)}")
            LOG.info(f"   â”” ì´ë¯¸ì§€ OCR í…ìŠ¤íŠ¸ ê¸¸ì´: {len(ocr_combined_text)}")
            LOG.info(f"   â”” ìµœì¢… full_content ê¸¸ì´: {len(post_copy['full_content'])}")
            
            aligned.append(post_copy)
            
        evaluated.append(post_copy)
    return aligned, evaluated

def notify(board: dict[str, str], posts: list[dict[str, Any]], recipients: list[dict[str, str]]) -> list[dict[str, Any]]:
    results: list[dict[str, Any]] = []
    for post in posts:
        title_prefix = "[ì í•©]" if post.get("aligned") else ""
        title = f"{title_prefix} ê³ ë ¤ëŒ€ ì •ë³´ëŒ€ ê³µì§€ ({board['name']})\n\n{post['title']}"
        
        for target in recipients:
            params = {
                "korean-title": title,
                "customer-name": target["name"],
                "article-link": post["link"],
            }
            try:
                data = send_kakao(target["contact"], TEMPLATE_CODE, params)
                results.append({
                    "board": board["name"],
                    "title": post["title"],
                    "recipient": target["contact"],
                    "status": data,
                })
            except Exception as exc:
                LOG.exception("Kakao send error: %s", exc)
                results.append({
                    "board": board["name"],
                    "title": post["title"],
                    "recipient": target["contact"],
                    "error": str(exc),
                })
    return results


def process_board(board: dict[str, str], base_url: str, profile_text: str, recipients: list[dict[str, str]]) -> dict[str, Any]:
    try:
        page_url, html = fetch_board(base_url, board)
        posts = parse_posts(html, page_url)
        aligned, evaluated = evaluate_posts(profile_text, board["name"], posts)
    except Exception as exc:
        LOG.exception("Board fetch error for %s: %s", board["name"], exc)
        return {"board": board["name"], "error": str(exc), "posts": [], "sent": [], "evaluated": []}
    
    # [ì„¤ì •] ì¹´ì¹´ì˜¤ ì „ì†¡ì„ ì ì‹œ ë§‰ê³  ì‹¶ì„ ë•Œ ì•„ë˜ë¥¼ ì£¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    # sent = notify(board, aligned, recipients) TODO 
    sent = [] 
    LOG.info(f"ğŸ“¢ [ì „ì†¡ ìŠ¤í‚µ] {board['name']} ì í•© ê³µì§€ {len(aligned)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
    
    return {"board": board["name"], "posts": aligned, "sent": sent, "evaluated": evaluated}

# í¬ë¡¤ë§ ëŒ€ìƒ ê²Œì‹œíŒ ì •ì˜ (ì½”ë“œ ìƒë‹¨ì— ì—†ë‹¤ë©´ ì¶”ê°€í•˜ì„¸ìš”)

def run(event: dict[str, Any], context: Any | None = None) -> dict[str, Any]:
    global RECIPIENTS_DEFAULT, BOARDS_DEFAULT
    logger.info("--- [CRAWLER START] ---")
    
    # 1. ì¸í’‹ ë°ì´í„° í™•ë³´
    user_profile = event.get("userProfile", {})
    profile_summary = user_profile.get("summary", "")
    target_url = event.get("targetUrl") or BASE_URL_DEFAULT
    recipients = event.get("recipients", RECIPIENTS_DEFAULT) # ê¸°ë³¸ ìˆ˜ì‹ ì ì‚¬ìš©
    
    base_url = normalize_base(target_url)
    
    # 2. ì‹¤í–‰ ëª¨ë“œ ê²°ì •
    # targetUrlì— íŠ¹ì • ì¹´í…Œê³ ë¦¬ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ ê²Œì‹œíŒë§Œ, ì•„ë‹ˆë©´ ì „ì²´ ìˆœíšŒ
    target_boards = BOARDS_DEFAULT
    for b in BOARDS_DEFAULT:
        if b['category'] in target_url:
            target_boards = [b]
            break

    all_reports = []
    
    # 3. í•µì‹¬ ì—”ì§„(process_board) ì‹¤í–‰
    for board in target_boards:
        LOG.info(f"ğŸš€ {board['name']} í¬ë¡¤ë§ ì‹œì‘...")
        report = process_board(board, base_url, profile_summary, recipients)
        all_reports.append(report)

    # 4. ìµœì¢… ì•„ì›ƒí’‹ ê·œê²© ì¡°ë¦½
    # ì—¬ëŸ¬ ê²Œì‹œíŒ ì¤‘ 'aligned'(ì í•©) íŒì •ëœ ê¸€ì´ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
    aligned_total = []
    for r in all_reports:
        aligned_total.extend(r.get("posts", []))

    if not aligned_total:
        return {
            "status": "SUCCESS",
            "relevanceScore": 0.0,
            "data": {"message": "ì í•©í•œ ìƒˆë¡œìš´ ê³µì§€ê°€ ì—†ìŠµë‹ˆë‹¤.", "timestamp": datetime.now(TIMEZONE).isoformat()}
        }

    # ê°€ì¥ ìµœì‹ /ì ìˆ˜ê°€ ë†’ì€ ê³µì§€ í•˜ë‚˜ë¥¼ ëŒ€í‘œë¡œ ë°˜í™˜ (ê·œê²© ì¤€ìˆ˜)
    best_post = aligned_total[0]
    
    response = {
        "status": "SUCCESS",
        "relevanceScore": 1.0, # aligned ë¦¬ìŠ¤íŠ¸ì— ë“¤ì–´ì™”ë‹¤ëŠ” ê±´ ì í•©í•˜ë‹¤ëŠ” ëœ»
        "data": {
            "category": best_post.get("category", "ê³µì§€"),
            "title": best_post["title"],
            "sourceName": "ê³ ë ¤ëŒ€í•™êµ ì •ë³´ëŒ€í•™",
            "summary": best_post.get("reason", "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"),
            "fullContent": best_post.get("full_content", ""), # OCR ê²°ê³¼ í¬í•¨
            "originalUrl": best_post["link"],
            "images": best_post.get("images", []),
            "timestamp": datetime.now(TIMEZONE).isoformat()
        }
    }

    logger.info(f"--- [CRAWLER END] ---")
    return response
if __name__ == "__main__":
    # 1. ë¡œê·¸ ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    LOG.info("ğŸš€ event.jsonì„ ì´ìš©í•œ ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 2. event.json íŒŒì¼ ì½ê¸°
    event_path = "event.json"
    if os.path.exists(event_path):
        with open(event_path, "r", encoding="utf-8") as f:
            try:
                event_data = json.load(f)
                LOG.info("âœ… event.json íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            except json.JSONDecodeError:
                LOG.error("âŒ event.json íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                sys.exit(1)
    else:
        # íŒŒì¼ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ìµœì†Œí•œì˜ ë”ë¯¸ ë°ì´í„°
        LOG.warning("âš ï¸ event.jsonì´ ì—†ì–´ ê¸°ë³¸ ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        event_data = {
            "userId": "test_user",
            "targetUrl": "https://info.korea.ac.kr/info/board/notice_under.do",
            "userProfile": {
                "summary": "ê³ ë ¤ëŒ€í•™êµ ì»´í“¨í„°í•™ê³¼ í•™ìƒ, AI í•´ì»¤í†¤ ë° ì¥í•™ê¸ˆì— ê´€ì‹¬ ìˆìŒ"
            },
            "config": {"language": "Korean"}
        }

    # 3. ì‹¤ì œ run í•¨ìˆ˜ ì‹¤í–‰
    try:
        # ìš°ë¦¬ê°€ ì •ì˜í•œ ì¸í’‹/ì•„ì›ƒí’‹ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” run í•¨ìˆ˜ í˜¸ì¶œ
        final_output = run(event_data)
        
        # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*50)
        print("ìµœì¢… API ì‘ë‹µ ê²°ê³¼ (Output):")
        print(json.dumps(final_output, ensure_ascii=False, indent=2))
        print("="*50)
        
    except Exception as e:
        LOG.error(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")