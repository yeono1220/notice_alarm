from __future__ import annotations

import pytesseract
from PIL import Image
from io import BytesIO
import json

import logging
import sys
import os
from datetime import datetime, timedelta
from typing import Any
from urllib.parse import urljoin
import requests
from bs4 import BeautifulSoup
from zoneinfo import ZoneInfo
import numpy as np
import cv2
from google import genai  # ì‹ í˜• ë¼ì´ë¸ŒëŸ¬ë¦¬

def preprocess_for_ocr(pil_img: Image.Image) -> Image.Image:
    img = np.array(pil_img)
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    _, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)
    return Image.fromarray(thresh)

pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'
def extract_text_from_image(img_url: str, parent_link: str) -> str:
    try:
        resp = session.get(img_url, timeout=HTTP_TIMEOUT)
        # ë¡œê·¸ì— ì›ë³¸ ê²Œì‹œê¸€ ë§í¬(parent_link)ë¥¼ í¬í•¨í•˜ì—¬ ì¶œë ¥
        LOG.info(f"ğŸ“¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„: {img_url} (ì¶œì²˜: {parent_link})")
        LOG.info(f"   â”” ì‘ë‹µ: {resp.status_code}, íƒ€ì…: {resp.headers.get('Content-Type')}")

        if "image" not in resp.headers.get("Content-Type", "").lower():
            LOG.error(f"   â”” ì‹¤íŒ¨: ì´ë¯¸ì§€ê°€ ì•„ë‹˜ ({img_url})")
            return ""

        img = Image.open(BytesIO(resp.content))
        processed = preprocess_for_ocr(img)

        text = pytesseract.image_to_string(
            processed,
            lang="kor+eng",
            config="--oem 3 --psm 6"
        )
        LOG.info(f"   â”” OCR ì²˜ë¦¬ ì™„ë£Œ (ê¸€ì ìˆ˜: {len(text.strip())})")
        return text.strip()
    except Exception as e:
        LOG.error(f"   â”” OCR ì‹¤íŒ¨ ({img_url}): {e}")
        return ""

# --- ì¶”ê°€ëœ 2ì°¨ í¬ë¡¤ë§ í•¨ìˆ˜ ---
def fetch_post_content(link: str) -> tuple[str, list[str]]:
    try:
        resp = session.get(link, timeout=HTTP_TIMEOUT)
        resp.encoding = 'utf-8'
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        
        # 1. ë³¸ë¬¸ ì˜ì—­ íƒìƒ‰ (ê°€ì¥ ì •í™•í•œ ì„ íƒì ìˆœì„œ)
        # ì •ë³´ëŒ€ ê²Œì‹œë¬¼ì€ ë³´í†µ .view-con ì•ˆì— .fr-viewê°€ ë“¤ì–´ìˆëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.
        content_area = (
            soup.select_one(".view-con") or 
            soup.select_one(".fr-view") or 
            soup.select_one(".article-view") or
            soup.select_one(".re-view")
        )
        
        if content_area:
            text = content_area.get_text(" ", strip=True)
            
            # 2. ì´ë¯¸ì§€ ì¶”ì¶œ (ë³´ì—¬ì£¼ì‹  íƒœê·¸ êµ¬ì¡° ë°˜ì˜)
            img_tags = content_area.find_all("img")
            img_urls = []
            
            for img in img_tags:
                # srcì™€ data-pathë¥¼ ëª¨ë‘ í™•ì¸
                src = img.get("src") or img.get("data-path")
                
                if src:
                    # í•„í„°ë§: ì—ë””í„° ì•„ì´ì½˜ì´ë‚˜ ì•„ì£¼ ì‘ì€ ì´ë¯¸ì§€ëŠ” ì œì™¸ (OCR íš¨ìœ¨ì„±)
                    if any(x in src for x in ["/icon/", "base64", "emoji"]):
                        continue
                    
                    # ìƒëŒ€ ê²½ë¡œ(/_res/...)ë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ê²°í•©
                    # urljoinì€ linkê°€ https://info.korea.ac.kr/... ì´ë¯€ë¡œ ì•Œì•„ì„œ í•©ì³ì¤ë‹ˆë‹¤.
                    full_url = urljoin(link, src)
                    img_urls.append(full_url)
            
            LOG.info(f"âœ… ì´ë¯¸ì§€ ê°ì§€ ì„±ê³µ: {len(img_urls)}ê°œ ë°œê²¬ (URL: {link})")
            return text, img_urls
            
        LOG.warning(f"âš ï¸ ë³¸ë¬¸ ì˜ì—­ íƒìƒ‰ ì‹¤íŒ¨: {link}")
        return "ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
        
    except Exception as e:
        LOG.error(f"âŒ 2ì°¨ í¬ë¡¤ë§ ì—ëŸ¬: {e}")
        return f"ì—ëŸ¬ ë°œìƒ: {e}", []
    
BASE_URL_DEFAULT = "https://info.korea.ac.kr/info/board/"
HTTP_TIMEOUT = float(os.getenv("HTTP_TIMEOUT", "15"))
SENDER_KEY = os.getenv("KAKAO_SENDER_KEY")
SECRET_KEY = os.getenv("KAKAO_SECRET_KEY")
APP_KEY = os.getenv("KAKAO_APP_KEY")
TEMPLATE_CODE = "send-article"
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)] 
)
LOG = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
LOOKBACK_DAYS = int(os.getenv("LOOKBACK_DAYS", "7"))
TIMEZONE = ZoneInfo("Asia/Seoul")

# [í•µì‹¬ ìˆ˜ì •] ì‹ í˜• ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì • ë°©ì‹
if GEMINI_API_KEY:
    client = genai.Client(api_key=GEMINI_API_KEY)
else:
    LOG.warning("GEMINI_API_KEY is missing!")
    client = None

def ask_ai(prompt: str) -> str:
    try:
        if not client: return "ERROR: NO CLIENT"
        
        # [ìˆ˜ì •] 2026ë…„ í‘œì¤€ ëª¨ë¸ëª…ê³¼ ì‹ ê·œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ ê·œê²© ì ìš©
        response = client.models.generate_content(
            model="gemini-2.0-flash", # 1.5-flash ëŒ€ì‹  2.0-flash ê¶Œì¥
            contents=prompt,
            config={
                'tools': [], # AFC ë“± ë¶ˆí•„ìš”í•œ ê¸°ëŠ¥ ì°¨ë‹¨ìœ¼ë¡œ í• ë‹¹ëŸ‰ ì ˆì•½
                'automatic_function_calling': {'disable': True}
            }
        )
        return response.text.strip()
    except Exception as e:
        LOG.error(f"AI í˜¸ì¶œ ì—ëŸ¬: {e}")
        return "ERROR"
def score_notice(profile_text: str, title: str, link: str) -> tuple[bool, str]:
    if not profile_text: return False, "no-profile"
    
    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê¸°ì¤€ì„ ì¡°ê¸ˆ ì™„í™”í•˜ê±°ë‚˜ ëª…í™•íˆ ì§€ì‹œ
    user_prompt = f"""
    Profile: {profile_text}
    Notice: {title}
    Analyze if this is relevant. Respond ONLY with 'YES' or 'NO'.
    """
    
    answer_text = ask_ai(user_prompt).upper()
    LOG.info(f"ğŸ¤– AI ë‹µë³€ ({title[:20]}...): {answer_text}")
    
    if "YES" in answer_text: return True, "YES"
    return False, "NO"

# ... (ë‚˜ë¨¸ì§€ send_kakao, fetch_board ë“± ê¸°ì¡´ í•¨ìˆ˜ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€) ...
# (ê¸°ì¡´ì— ì˜ ëŒì•„ê°€ë˜ íŒŒì‹± ë° ì•Œë¦¼ ë¡œì§ì€ ê·¸ëŒ€ë¡œ ë‘ì…”ë„ ë©ë‹ˆë‹¤)
BASE_URL_DEFAULT = "https://info.korea.ac.kr/info/board/"
HTTP_TIMEOUT = float(os.getenv("HTTP_TIMEOUT", "15"))

# [ë³€ê²½] OpenAI ì„¤ì • ì œê±° ë° Gemini ì„¤ì • ì¶”ê°€


RECIPIENTS_DEFAULT = [
    {"name": "ê³ ë ¤ëŒ€ í•™ë¶€ìƒ ê¹€ìˆ˜ê²¸", "contact": "01068584123"},
    {"name": "ê³ ë ¤ëŒ€ í•™ë¶€ìƒ ê³ ì—°ì˜¤", "contact": "01026570090"},
]

BOARDS_DEFAULT = [
    {"name": "í•™ë¶€ê³µì§€", "category": "notice_under"},
    {"name": "í•™ë¶€ì¥í•™", "category": "scholarship_under"},
    {"name": "ì •ë³´ëŒ€ì†Œì‹", "category": "news"},
    {"name": "ì·¨ì—…ì •ë³´", "category": "course_job"},
    {"name": "í”„ë¡œê·¸ë¨", "category": "course_program"},
    {"name": "ì¸í„´ì‹­", "category": "course_intern"},
    {"name": "ê³µëª¨ì „", "category": "course_competition"},
]

session = requests.Session()


def normalize_base(url: str | None) -> str:
    if not url:
        return BASE_URL_DEFAULT
    trimmed = url.strip()
    if trimmed.endswith(".do"):
        trimmed = trimmed[: trimmed.rfind("/") + 1]
    return f"{trimmed.rstrip('/')}/"

# [ì¶”ê°€] AI ì œê³µìë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„ íƒ (ê¸°ë³¸ê°’: gemini)
AI_PROVIDER = os.getenv("AI_PROVIDER", "gemini").lower() 
# OpenAI í‚¤ë„ í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ ë¶ˆëŸ¬ì˜¤ê¸° (ë‚˜ì¤‘ì„ ìœ„í•´)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = genai.Client(api_key=GEMINI_API_KEY) if GEMINI_API_KEY else None
# app/jobs/korea_university.py ë‚´ send_kakao ìˆ˜ì •

# app/jobs/korea_university.py ì˜ send_kakao í•¨ìˆ˜ ìˆ˜ì •
def send_kakao(contact: str, template_code: str, template_param: dict[str, str]) -> dict[str, Any]:
    payload = {
        "senderKey": SENDER_KEY,
        "templateCode": template_code,
        "recipientList": [{"recipientNo": contact, "templateParameter": template_param}],
    }
    headers = {"X-Secret-Key": SECRET_KEY, "Content-Type": "application/json;charset=UTF-8"}
    url = f"https://api-alimtalk.cloud.toast.com/alimtalk/v2.2/appkeys/{APP_KEY}/messages"
    
    try:
        # [ìˆ˜ì •] POST ìš”ì²­ì´ ë¨¼ì € ì™€ì•¼ í•©ë‹ˆë‹¤.
        resp = session.post(url, json=payload, headers=headers, timeout=HTTP_TIMEOUT)
        # [ìˆ˜ì •] ê·¸ í›„ì— ë¡œê·¸ë¥¼ ì°ì–´ì•¼ NameErrorê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        LOG.info(f"Kakao API ì‘ë‹µ ìƒíƒœ: {resp.status_code}")
        LOG.info(f"Kakao API ì‘ë‹µ ë³¸ë¬¸: {resp.text}")
        if resp.status_code != 200:
            LOG.error("Kakao send failed (%s) %s", resp.status_code, resp.text)
            return {"error": "API_STATUS_ERROR", "status": resp.status_code}
            
        return resp.json() if "application/json" in resp.headers.get("Content-Type", "") else {"status": resp.status_code}
    except Exception as e:
        LOG.error("Kakao connection error: %s", e)
        return {"error": str(e)}
def fetch_board(base_url: str, board: dict[str, str]) -> tuple[str, str]:
    page_url = f"{base_url}{board['category']}.do"
    resp = session.get(page_url, timeout=HTTP_TIMEOUT)
    resp.raise_for_status()
    return page_url, resp.text


def parse_posts(html: str, page_url: str) -> list[dict[str, str]]:
    soup = BeautifulSoup(html, "html.parser")
    today = datetime.now(TIMEZONE).date()
    cutoff = today - timedelta(days=LOOKBACK_DAYS - 1)
    posts: list[dict[str, str]] = []
    
    for row in soup.select("tr"):
        cells = row.find_all("td")
        if not cells:
            continue
        
        # ë‚ ì§œ íŒŒì‹± (ê³ ë ¤ëŒ€ í˜•ì‹: YYYY.MM.DD)
        date_text = cells[-1].get_text(strip=True)
        try:
            row_date = datetime.strptime(date_text, "%Y.%m.%d").date()
        except ValueError:
            continue
            
        if row_date < cutoff:
            continue
            
        link_tag = row.select_one("a.article-title")
        if not link_tag:
            continue
            
        href = (link_tag.get("href") or "").replace("amp;", "")
        title = link_tag.get_text(strip=True)
        posts.append({"title": title, "link": urljoin(page_url, href)})
        
    return posts


def evaluate_posts(profile_text: str, board_name: str, posts: list[dict[str, str]]) -> tuple[list[dict[str, Any]], list[dict[str, Any]]]:
    aligned: list[dict[str, Any]] = []
    evaluated: list[dict[str, Any]] = []
    
    for post in posts:
        post_copy = dict(post)
        decision, rationale = score_notice(profile_text, post_copy["title"], post_copy["link"])
        post_copy["reason"] = rationale
        post_copy["aligned"] = decision
        
        # í•„ë“œ ì´ˆê¸°í™”
        post_copy["full_content"] = ""
        post_copy["images"] = []

        if decision: 
            LOG.info(f"ğŸ” [ë¶„ì„ ì‹œì‘] ì œëª©: {post_copy['title']}")
            full_text, img_urls = fetch_post_content(post_copy["link"])
            
            ocr_combined_text = ""
            for idx, url in enumerate(img_urls):
                # ì´ë¯¸ì§€ë³„ë¡œ ìˆœë²ˆê³¼ ë§í¬ë¥¼ ë¡œê·¸ì— ë‚¨ê¹€
                ocr_result = extract_text_from_image(url, post_copy["link"])
                if ocr_result:
                    ocr_combined_text += f"\n\n--- [ì´ë¯¸ì§€ #{idx+1} í…ìŠ¤íŠ¸ ì‹œì‘] ---\n{ocr_result}\n--- [ì´ë¯¸ì§€ #{idx+1} í…ìŠ¤íŠ¸ ë] ---\n"
            
            # ìµœì¢… ê²°í•© ë° í• ë‹¹
            post_copy["full_content"] = (full_text + ocr_combined_text).strip()
            post_copy["images"] = img_urls

            # ë¡œê·¸ë¡œ ê²°í•© ê²°ê³¼ í™•ì¸
            LOG.info(f"ğŸ“Š [ê²°í•© ì™„ë£Œ] {post_copy['title']}")
            LOG.info(f"   â”” ë³¸ë¬¸ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_text)}")
            LOG.info(f"   â”” ì´ë¯¸ì§€ OCR í…ìŠ¤íŠ¸ ê¸¸ì´: {len(ocr_combined_text)}")
            LOG.info(f"   â”” ìµœì¢… full_content ê¸¸ì´: {len(post_copy['full_content'])}")
            
            aligned.append(post_copy)
            
        evaluated.append(post_copy)
    return aligned, evaluated

def notify(board: dict[str, str], posts: list[dict[str, Any]], recipients: list[dict[str, str]]) -> list[dict[str, Any]]:
    results: list[dict[str, Any]] = []
    for post in posts:
        title_prefix = "[ì í•©]" if post.get("aligned") else ""
        title = f"{title_prefix} ê³ ë ¤ëŒ€ ì •ë³´ëŒ€ ê³µì§€ ({board['name']})\n\n{post['title']}"
        
        for target in recipients:
            params = {
                "korean-title": title,
                "customer-name": target["name"],
                "article-link": post["link"],
            }
            try:
                data = send_kakao(target["contact"], TEMPLATE_CODE, params)
                results.append({
                    "board": board["name"],
                    "title": post["title"],
                    "recipient": target["contact"],
                    "status": data,
                })
            except Exception as exc:
                LOG.exception("Kakao send error: %s", exc)
                results.append({
                    "board": board["name"],
                    "title": post["title"],
                    "recipient": target["contact"],
                    "error": str(exc),
                })
    return results


def process_board(board: dict[str, str], base_url: str, profile_text: str, recipients: list[dict[str, str]]) -> dict[str, Any]:
    try:
        page_url, html = fetch_board(base_url, board)
        posts = parse_posts(html, page_url)
        aligned, evaluated = evaluate_posts(profile_text, board["name"], posts)
    except Exception as exc:
        LOG.exception("Board fetch error for %s: %s", board["name"], exc)
        return {"board": board["name"], "error": str(exc), "posts": [], "sent": [], "evaluated": []}
    
    # [ì„¤ì •] ì¹´ì¹´ì˜¤ ì „ì†¡ì„ ì ì‹œ ë§‰ê³  ì‹¶ì„ ë•Œ ì•„ë˜ë¥¼ ì£¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    # sent = notify(board, aligned, recipients) TODO 
    sent = [] 
    LOG.info(f"ğŸ“¢ [ì „ì†¡ ìŠ¤í‚µ] {board['name']} ì í•© ê³µì§€ {len(aligned)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
    
    return {"board": board["name"], "posts": aligned, "sent": sent, "evaluated": evaluated}

# app/jobs/korea_university.py ì˜ run í•¨ìˆ˜ ìˆ˜ì • ì œì•ˆ
def run(event: dict[str, Any], context: Any | None = None) -> dict[str, Any]:
    payload = event or {}
    # 1. ìš°ì„ ìˆœìœ„: event ì „ë‹¬ê°’ -> í™˜ê²½ë³€ìˆ˜ -> ë¡œì»¬ íŒŒì¼
    profile_text = payload.get("user_profile") or os.getenv("USER_PROFILE")
    
    if not profile_text:
        try:
            # Dockerfileì—ì„œ ë³µì‚¬ëœ user_profile.json í™•ì¸
            profile_path = os.getenv("PROFILE_PATH", "user_profile.json")
            with open(profile_path, "r", encoding="utf-8") as f:
                try:
                    data = json.load(f)
                    profile_text = data.get("summary") or data.get("profile") or str(data)
                except json.JSONDecodeError:
                    f.seek(0)
                    profile_text = f.read()
        except Exception as e:
            LOG.error(f"í”„ë¡œí•„ ë¡œë“œ ì‹¤íŒ¨: {e}")

    if not profile_text:
        return {"error": "user_profile is required and not found"}

    # --- ì‹¤ì œ í¬ë¡¤ë§ ì‹¤í–‰ ë¡œì§ ---
    base_url = payload.get("base_url") or BASE_URL_DEFAULT
    all_results = []

    for board in BOARDS_DEFAULT:
        LOG.info(f"ğŸš€ {board['name']} í¬ë¡¤ë§ ì‹œì‘...")
        # process_board ë‚´ë¶€ì—ì„œ fetch_post_contentì™€ ì´ë¯¸ì§€ OCRì´ ì‹¤í–‰ë¨
        result = process_board(board, base_url, profile_text, RECIPIENTS_DEFAULT)
        all_results.append(result)

    LOG.info(f"âœ… ì´ {len(all_results)}ê°œ ê²Œì‹œíŒ ì‘ì—… ì™„ë£Œ")
    return {"status": "success", "results": all_results}

# app/jobs/korea_university.py í•˜ë‹¨ ìˆ˜ì • ì œì•ˆ

if __name__ == "__main__":
    # 1. ë¡œê·¸ ë ˆë²¨ì„ ê°•ì œë¡œ INFOë¡œ ì„¤ì •í•˜ì—¬ ì¶œë ¥ í™•ì¸
    logging.basicConfig(level=logging.INFO)
    LOG.info("ğŸš€ í¬ë¡¤ë§ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 2. ë¡œì»¬ íŒŒì¼ì´ë‚˜ í™˜ê²½ ë³€ìˆ˜ì—ì„œ í”„ë¡œí•„ ë¡œë“œ ì‹œë„
    profile_text = os.getenv("USER_PROFILE")
    if not profile_text:
        profile_path = os.getenv("PROFILE_PATH", "user_profile.json")
        if os.path.exists(profile_path):
            with open(profile_path, "r", encoding="utf-8") as f:
                profile_text = f.read()
    
    # 3. í”„ë¡œí•„ì´ ì—†ë”ë¼ë„ í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°ë¡œë¼ë„ ì‹¤í–‰ ê°•ì œ
    if not profile_text:
        LOG.warning("âš ï¸ í”„ë¡œí•„ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ í…ŒìŠ¤íŠ¸ í”„ë¡œí•„ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        profile_text = "ê³ ë ¤ëŒ€í•™êµ ì»´í“¨í„°í•™ê³¼ í•™ìƒ, AI í•´ì»¤í†¤ ë° ì¥í•™ê¸ˆì— ê´€ì‹¬ ìˆìŒ"

    # 4. ì‹¤ì œ ì‹¤í–‰
    event_data = {
        "user_profile": profile_text,
        "base_url": BASE_URL_DEFAULT
    }
    
    try:
        # ëª¨ë“  ê²Œì‹œíŒ ìˆœíšŒ ì‹¤í–‰
        results = []
        for board in BOARDS_DEFAULT:
            res = process_board(board, BASE_URL_DEFAULT, profile_text, RECIPIENTS_DEFAULT)
            results.append(res)
        
        # ê²°ê³¼ ì¶œë ¥ (ì´ ë¡œê·¸ê°€ Cloud Runì— ë‚¨ì•„ì•¼ í•¨)
        print(json.dumps({"results": results}, ensure_ascii=False, indent=2))
        LOG.info("âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        LOG.error(f"âŒ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")